{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOw3AIKY/Hu68UQqLz0eD6y"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["### Estimating MLE through PyTorch\n","\n","- Generate data from a Poisson regression\n","- Create a loglikelihood function for the parameters\n","- Create the score function for the parameters using autograd on the loglikelihood\n","- Create the Hessian function for the parameters using autograd on the score function\n","- Use gradient descent to find MLE estimates and invert Hessian to estimate SEs\n","- Compare results with estimates from GLM package\n","\n","\n"],"metadata":{"id":"goqnS14_lOe2"}},{"cell_type":"code","source":["# Packages\n","import torch\n","import numpy as np\n","import warnings\n","warnings.filterwarnings('ignore')\n","\n","# Data\n","n = 10000\n","x = np.random.uniform(0,1,(n,2))\n","beta = np.array([1.0,1.8])\n","lmbda = np.exp(np.dot(x, beta))\n","y = np.random.poisson(lmbda, n)\n","print(beta, lmbda[0:5])\n","print(np.c_[y, x][0:5])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"azueXci7vacc","executionInfo":{"status":"ok","timestamp":1704971902093,"user_tz":300,"elapsed":182,"user":{"displayName":"Pranjal","userId":"04981331918725041814"}},"outputId":"a1b0f119-ba05-49c1-f733-bdda8ad05684"},"execution_count":82,"outputs":[{"output_type":"stream","name":"stdout","text":["[1.  1.8] [10.38737376  5.61436557  4.25111613  3.76185124  3.52810146]\n","[[ 8.          0.66646649  0.93006917]\n"," [10.          0.45443313  0.70605304]\n"," [ 1.          0.30554685  0.63424151]\n"," [ 1.          0.58640304  0.4102823 ]\n"," [ 4.          0.0520169   0.67152389]]\n"]}]},{"cell_type":"code","source":["beta = torch.tensor(beta)\n","x = torch.tensor(x)\n","y = torch.tensor(y)\n","\n","def neglogLik(beta, x, y):\n","    \"\"\"Constructs the loglikelihood of the parameters given the data\"\"\"\n","    log_lambda = torch.matmul(x, beta)\n","    negloglikelihood = -torch.sum(y * log_lambda - torch.exp(log_lambda))\n","    # R broadcasting a * b differ from Python broadcasting rules\n","    return negloglikelihood\n","\n","def score(beta):\n","    \"\"\"Computes the gradient of the loglikelihood i.e. the score vector\"\"\"\n","    beta_tensor = torch.tensor(beta, requires_grad = True)\n","    negloglikelihood = neglogLik(beta_tensor, x, y)\n","    score = torch.autograd.grad(negloglikelihood, beta_tensor)[0]\n","    return score\n","\n","def hessian(beta):\n","    \"\"\"Computes the second derivative of the loglikelihood function i.e. the Hessian matrix\"\"\"\n","    beta_tensor = torch.tensor(beta, requires_grad = True)\n","    negloglikelihood = lambda b: neglogLik(b, x, y)\n","    hess = torch.autograd.functional.hessian(negloglikelihood, beta_tensor)\n","    return hess\n","\n","def varcov(beta):\n","    \"\"\"Inverts the Hessian to get the Standard Errors\"\"\"\n","    fisherInformation = hessian(beta)\n","    stderr = torch.sqrt(torch.diagonal(torch.linalg.inv(fisherInformation)))\n","    return stderr.numpy()\n","\n","def evalLoss(beta):\n","    negloglikelihood = neglogLik(torch.tensor(beta), x, y).item()\n","    return negloglikelihood\n","\n","def evalGrad(beta):\n","    grad = score(torch.tensor(beta))\n","    return grad\n","\n","def evalHess(beta):\n","    hess = hessian(torch.tensor(beta))\n","    return hess\n","\n","print('neglogLik', neglogLik(beta, x, y))\n","print('score', score(beta))\n","print('hessian', hessian(beta))\n","print('loss',evalLoss(beta))\n","print('grad',evalGrad(beta))\n","print('hess',evalHess(beta))\n","print('varcov',varcov(beta+0.01))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2gD9azFuyEV5","executionInfo":{"status":"ok","timestamp":1704971902991,"user_tz":300,"elapsed":147,"user":{"displayName":"Pranjal","userId":"04981331918725041814"}},"outputId":"27b07711-6d26-4209-8c9f-e1c6df1e45ff"},"execution_count":83,"outputs":[{"output_type":"stream","name":"stdout","text":["neglogLik tensor(-36038.6777, dtype=torch.float64)\n","score tensor([-143.7124, -188.2054], dtype=torch.float64)\n","hessian tensor([[20033.6765, 17983.0118],\n","        [17983.0118, 23308.0256]], dtype=torch.float64)\n","loss -36038.67768981711\n","grad tensor([-143.7124, -188.2054], dtype=torch.float64)\n","hess tensor([[20033.6765, 17983.0118],\n","        [17983.0118, 23308.0256]], dtype=torch.float64)\n","varcov [0.01266956 0.01174804]\n"]}]},{"cell_type":"code","source":["print(beta)\n","\n","from scipy.optimize import minimize\n","beta_init = np.array([1,2])\n","res = minimize(evalLoss, beta_init, tol = 1e-12, method='BFGS', jac=evalGrad)\n","print(res.x)\n","print(varcov(res.x))\n","\n","from scipy.optimize import minimize\n","beta_init = np.array([0,0])\n","res = minimize(evalLoss, beta_init, tol = 1e-12, method='Newton-CG', jac=evalGrad, hess=evalHess)\n","print(res.x)\n","print(varcov(res.x))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wWymVQ54j-CP","executionInfo":{"status":"ok","timestamp":1704971903218,"user_tz":300,"elapsed":4,"user":{"displayName":"Pranjal","userId":"04981331918725041814"}},"outputId":"56f6a706-cab4-490b-a9f2-b11728790c4c"},"execution_count":84,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([1.0000, 1.8000], dtype=torch.float64)\n","[0.99976332 1.80823107]\n","[0.01271626 0.01178099]\n","[0.99976332 1.80823107]\n","[0.01271626 0.01178099]\n"]}]},{"cell_type":"markdown","source":["### Evaluate"],"metadata":{"id":"drE0NZC96Iq4"}},{"cell_type":"code","source":["import statsmodels.api as sm\n","import statsmodels.formula.api as smf\n","import pandas as pd\n","df = pd.DataFrame(np.c_[y,x], columns = ['y','x1', 'x2'])\n","print(smf.glm('y ~ x1 + x2 - 1', df, family=sm.families.Poisson()).fit().summary())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GLUzabhuvYVi","executionInfo":{"status":"ok","timestamp":1704971904846,"user_tz":300,"elapsed":160,"user":{"displayName":"Pranjal","userId":"04981331918725041814"}},"outputId":"d5ae0733-aa73-45bc-db45-978b9033943c"},"execution_count":85,"outputs":[{"output_type":"stream","name":"stdout","text":["                 Generalized Linear Model Regression Results                  \n","==============================================================================\n","Dep. Variable:                      y   No. Observations:                10000\n","Model:                            GLM   Df Residuals:                     9998\n","Model Family:                 Poisson   Df Model:                            1\n","Link Function:                    Log   Scale:                          1.0000\n","Method:                          IRLS   Log-Likelihood:                -21000.\n","Date:                Thu, 11 Jan 2024   Deviance:                       10886.\n","Time:                        11:18:24   Pearson chi2:                 1.02e+04\n","No. Iterations:                     5   Pseudo R-squ. (CS):             0.7916\n","Covariance Type:            nonrobust                                         \n","==============================================================================\n","                 coef    std err          z      P>|z|      [0.025      0.975]\n","------------------------------------------------------------------------------\n","x1             0.9998      0.013     78.621      0.000       0.975       1.025\n","x2             1.8082      0.012    153.487      0.000       1.785       1.831\n","==============================================================================\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"wUL4qlmfPqXf"},"execution_count":null,"outputs":[]}]}