{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "e8a6fe4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "df = pd.read_csv('/Users/pranjal/Desktop/Causal-Inference/data/wage.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "e94c8179",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(753, 22)"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "551f9baa",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat = df.select_dtypes('object').columns\n",
    "df = pd.get_dummies(df, columns = cat, drop_first = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "7c137ea8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['inlf', 'hours', 'kidslt6', 'kidsge6', 'age', 'educ', 'wage', 'repwage',\n",
       "       'hushrs', 'husage', 'huseduc', 'huswage', 'faminc', 'mtr', 'motheduc',\n",
       "       'fatheduc', 'unem', 'city', 'exper', 'nwifeinc', 'lwage', 'expersq'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "8957f6e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "outcome = 'lwage'\n",
    "treatment = 'educ'\n",
    "rest = list(df.drop([outcome, treatment], axis = 1).columns)\n",
    "rest = ['exper','age', 'kidslt6', 'kidsge6']\n",
    "df = df[[outcome] + [treatment] + rest]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "e10c68a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(428, 6)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>exper</th>\n",
       "      <th>age</th>\n",
       "      <th>kidslt6</th>\n",
       "      <th>kidsge6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   exper   age  kidslt6  kidsge6\n",
       "0   14.0  32.0      1.0      0.0\n",
       "1    5.0  30.0      0.0      2.0\n",
       "2   15.0  35.0      1.0      3.0\n",
       "3    6.0  34.0      0.0      3.0\n",
       "4    7.0  31.0      1.0      2.0"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#import wooldridge\n",
    "#df = wooldridge.data('jtrain3')\n",
    "#df['avg'] = 0.5 * (df.re74+df.re75)\n",
    "df = df.dropna()\n",
    "#df = df.fillna(0)\n",
    "#df = df[df.avg <= 15]\n",
    "y = df[outcome]\n",
    "d = df[treatment]\n",
    "x = df[rest].astype('float')\n",
    "print(df.shape)\n",
    "x.head()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "f57cea98",
   "metadata": {},
   "source": [
    "# Simple Comparision of Means\n",
    "import statsmodels.api as sm\n",
    "mod = sm.OLS(y, sm.add_constant(np.c_[d], prepend=False))\n",
    "res = mod.fit()\n",
    "print(res.summary())\n",
    "print(res.params[0])\n",
    "print(res.bse[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4e0609f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "8167540c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                  lwage   R-squared:                       0.151\n",
      "Model:                            OLS   Adj. R-squared:                  0.141\n",
      "Method:                 Least Squares   F-statistic:                     14.98\n",
      "Date:                Tue, 06 Dec 2022   Prob (F-statistic):           1.52e-13\n",
      "Time:                        13:51:16   Log-Likelihood:                -433.15\n",
      "No. Observations:                 428   AIC:                             878.3\n",
      "Df Residuals:                     422   BIC:                             902.6\n",
      "Df Model:                           5                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "x1             0.1096      0.014      7.600      0.000       0.081       0.138\n",
      "x2             0.0155      0.005      3.261      0.001       0.006       0.025\n",
      "x3            -0.0035      0.005     -0.666      0.505      -0.014       0.007\n",
      "x4            -0.0755      0.089     -0.851      0.395      -0.250       0.099\n",
      "x5            -0.0177      0.028     -0.632      0.528      -0.073       0.037\n",
      "const         -0.2190      0.300     -0.729      0.466      -0.809       0.371\n",
      "==============================================================================\n",
      "Omnibus:                       79.021   Durbin-Watson:                   1.985\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              299.257\n",
      "Skew:                          -0.773   Prob(JB):                     1.04e-65\n",
      "Kurtosis:                       6.793   Cond. No.                         433.\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "0.10960057197002461\n",
      "0.014420407654629075\n"
     ]
    }
   ],
   "source": [
    "# Pooled Regression Adjustment\n",
    "import statsmodels.api as sm\n",
    "mod = sm.OLS(y, sm.add_constant(np.c_[d, x], prepend=False))\n",
    "res = mod.fit()\n",
    "print(res.summary())\n",
    "print(res.params[0])\n",
    "print(res.bse[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "b81abedb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficient Results:  X is None, please call intercept_inference to learn the constant!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>CATE Intercept Results</caption>\n",
       "<tr>\n",
       "         <td></td>        <th>point_estimate</th> <th>stderr</th> <th>zstat</th> <th>pvalue</th> <th>ci_lower</th> <th>ci_upper</th>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>cate_intercept</th>      <td>0.109</td>      <td>0.014</td> <td>7.935</td>   <td>0.0</td>    <td>0.082</td>    <td>0.136</td> \n",
       "</tr>\n",
       "</table><br/><br/><sub>A linear parametric conditional average treatment effect (CATE) model was fitted:<br/>$Y = \\Theta(X)\\cdot T + g(X, W) + \\epsilon$<br/>where for every outcome $i$ and treatment $j$ the CATE $\\Theta_{ij}(X)$ has the form:<br/>$\\Theta_{ij}(X) = X' coef_{ij} + cate\\_intercept_{ij}$<br/>Coefficient Results table portrays the $coef_{ij}$ parameter vector for each outcome $i$ and treatment $j$. Intercept Results table portrays the $cate\\_intercept_{ij}$ parameter.</sub>"
      ],
      "text/plain": [
       "<class 'econml.utilities.Summary'>\n",
       "\"\"\"\n",
       "                       CATE Intercept Results                      \n",
       "===================================================================\n",
       "               point_estimate stderr zstat pvalue ci_lower ci_upper\n",
       "-------------------------------------------------------------------\n",
       "cate_intercept          0.109  0.014 7.935    0.0    0.082    0.136\n",
       "-------------------------------------------------------------------\n",
       "\n",
       "<sub>A linear parametric conditional average treatment effect (CATE) model was fitted:\n",
       "$Y = \\Theta(X)\\cdot T + g(X, W) + \\epsilon$\n",
       "where for every outcome $i$ and treatment $j$ the CATE $\\Theta_{ij}(X)$ has the form:\n",
       "$\\Theta_{ij}(X) = X' coef_{ij} + cate\\_intercept_{ij}$\n",
       "Coefficient Results table portrays the $coef_{ij}$ parameter vector for each outcome $i$ and treatment $j$. Intercept Results table portrays the $cate\\_intercept_{ij}$ parameter.</sub>\n",
       "\"\"\""
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# DML regression - still yeilds unbiased estimate of ATE \n",
    "from econml.dml import LinearDML\n",
    "est = LinearDML(random_state=1)\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "est = LinearDML(discrete_treatment=False, cv=10)\n",
    "est.fit(y.ravel(), d.ravel(), X=None,W=x)\n",
    "est.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "9116c1b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficient Results:  X is None, please call intercept_inference to learn the constant!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>CATE Intercept Results</caption>\n",
       "<tr>\n",
       "         <td></td>        <th>point_estimate</th> <th>stderr</th> <th>zstat</th> <th>pvalue</th> <th>ci_lower</th> <th>ci_upper</th>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>cate_intercept</th>      <td>0.116</td>      <td>0.014</td> <td>8.434</td>   <td>0.0</td>    <td>0.089</td>    <td>0.143</td> \n",
       "</tr>\n",
       "</table><br/><br/><sub>A linear parametric conditional average treatment effect (CATE) model was fitted:<br/>$Y = \\Theta(X)\\cdot T + g(X, W) + \\epsilon$<br/>where for every outcome $i$ and treatment $j$ the CATE $\\Theta_{ij}(X)$ has the form:<br/>$\\Theta_{ij}(X) = X' coef_{ij} + cate\\_intercept_{ij}$<br/>Coefficient Results table portrays the $coef_{ij}$ parameter vector for each outcome $i$ and treatment $j$. Intercept Results table portrays the $cate\\_intercept_{ij}$ parameter.</sub>"
      ],
      "text/plain": [
       "<class 'econml.utilities.Summary'>\n",
       "\"\"\"\n",
       "                       CATE Intercept Results                      \n",
       "===================================================================\n",
       "               point_estimate stderr zstat pvalue ci_lower ci_upper\n",
       "-------------------------------------------------------------------\n",
       "cate_intercept          0.116  0.014 8.434    0.0    0.089    0.143\n",
       "-------------------------------------------------------------------\n",
       "\n",
       "<sub>A linear parametric conditional average treatment effect (CATE) model was fitted:\n",
       "$Y = \\Theta(X)\\cdot T + g(X, W) + \\epsilon$\n",
       "where for every outcome $i$ and treatment $j$ the CATE $\\Theta_{ij}(X)$ has the form:\n",
       "$\\Theta_{ij}(X) = X' coef_{ij} + cate\\_intercept_{ij}$\n",
       "Coefficient Results table portrays the $coef_{ij}$ parameter vector for each outcome $i$ and treatment $j$. Intercept Results table portrays the $cate\\_intercept_{ij}$ parameter.</sub>\n",
       "\"\"\""
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# DML regression - still yeilds unbiased estimate of ATE \n",
    "from econml.dml import LinearDML\n",
    "est = LinearDML(random_state=1)\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "est = LinearDML(discrete_treatment=False, model_y = RandomForestRegressor(), model_t = RandomForestRegressor(), cv = 10)\n",
    "est.fit(y.ravel(), d.ravel(), X=None,W=x)\n",
    "est.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f1352e3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "a72d3881",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================== DoubleMLData Object ==================\n",
      "\n",
      "------------------ Data summary      ------------------\n",
      "Outcome variable: lwage\n",
      "Treatment variable(s): ['educ']\n",
      "Covariates: ['exper', 'age', 'kidslt6', 'kidsge6']\n",
      "Instrument variable(s): None\n",
      "No. Observations: 428\n",
      "\n",
      "------------------ DataFrame info    ------------------\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 428 entries, 0 to 427\n",
      "Columns: 6 entries, lwage to kidsge6\n",
      "dtypes: float64(1), int64(5)\n",
      "memory usage: 23.4 KB\n",
      "\n",
      "================== DoubleMLPLR Object ==================\n",
      "\n",
      "------------------ Data summary      ------------------\n",
      "Outcome variable: lwage\n",
      "Treatment variable(s): ['educ']\n",
      "Covariates: ['exper', 'age', 'kidslt6', 'kidsge6']\n",
      "Instrument variable(s): None\n",
      "No. Observations: 428\n",
      "\n",
      "------------------ Score & algorithm ------------------\n",
      "Score function: partialling out\n",
      "DML algorithm: dml2\n",
      "\n",
      "------------------ Machine learner   ------------------\n",
      "Learner ml_l: RandomForestRegressor(max_depth=8, max_features='sqrt', n_estimators=500)\n",
      "Learner ml_m: RandomForestRegressor(max_depth=8, max_features='sqrt', n_estimators=500)\n",
      "\n",
      "------------------ Resampling        ------------------\n",
      "No. folds: 5\n",
      "No. repeated sample splits: 1\n",
      "Apply cross-fitting: True\n",
      "\n",
      "------------------ Fit summary       ------------------\n",
      "          coef   std err         t         P>|t|     2.5 %    97.5 %\n",
      "educ  0.096905  0.013844  6.999778  2.563684e-12  0.069771  0.124039\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from doubleml.datasets import make_plr_CCDDHNR2018\n",
    "from doubleml import DoubleMLData\n",
    "\n",
    "np.random.seed(1234)\n",
    "dml_data_bonus = DoubleMLData(df, y_col=outcome,\n",
    "                                  d_cols=treatment,\n",
    "                                  x_cols=list(rest))\n",
    "print(dml_data_bonus)\n",
    "from sklearn.base import clone\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LassoCV\n",
    "learner = RandomForestRegressor(n_estimators = 500, max_features = 'sqrt', max_depth= 8)\n",
    "ml_l_bonus = clone(learner)\n",
    "ml_m_bonus = clone(learner)\n",
    "learner = LassoCV()\n",
    "ml_l_sim = clone(learner)\n",
    "ml_m_sim = clone(learner)\n",
    "def non_orth_score(y, d, l_hat, m_hat, g_hat, smpls):\n",
    "    u_hat = y - g_hat\n",
    "    psi_a = -np.multiply(d, d)\n",
    "    psi_b = np.multiply(d, u_hat)\n",
    "    return psi_a, psi_b\n",
    "\n",
    "from doubleml import DoubleMLPLR\n",
    "np.random.seed(3141)\n",
    "obj_dml_plr_bonus = DoubleMLPLR(dml_data_bonus, ml_l_bonus, ml_m_bonus)\n",
    "obj_dml_plr_bonus.fit();\n",
    "print(obj_dml_plr_bonus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "747d7da8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================== DoubleMLData Object ==================\n",
      "\n",
      "------------------ Data summary      ------------------\n",
      "Outcome variable: lwage\n",
      "Treatment variable(s): ['educ']\n",
      "Covariates: ['exper', 'age', 'kidslt6', 'kidsge6']\n",
      "Instrument variable(s): None\n",
      "No. Observations: 428\n",
      "\n",
      "------------------ DataFrame info    ------------------\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 428 entries, 0 to 427\n",
      "Columns: 6 entries, lwage to kidsge6\n",
      "dtypes: float64(1), int64(5)\n",
      "memory usage: 23.4 KB\n",
      "\n",
      "================== DoubleMLPLR Object ==================\n",
      "\n",
      "------------------ Data summary      ------------------\n",
      "Outcome variable: lwage\n",
      "Treatment variable(s): ['educ']\n",
      "Covariates: ['exper', 'age', 'kidslt6', 'kidsge6']\n",
      "Instrument variable(s): None\n",
      "No. Observations: 428\n",
      "\n",
      "------------------ Score & algorithm ------------------\n",
      "Score function: partialling out\n",
      "DML algorithm: dml2\n",
      "\n",
      "------------------ Machine learner   ------------------\n",
      "Learner ml_l: RandomForestRegressor(max_depth=6, max_features='sqrt')\n",
      "Learner ml_m: RandomForestRegressor(max_depth=6, max_features='sqrt')\n",
      "\n",
      "------------------ Resampling        ------------------\n",
      "No. folds: 10\n",
      "No. repeated sample splits: 1\n",
      "Apply cross-fitting: True\n",
      "\n",
      "------------------ Fit summary       ------------------\n",
      "          coef   std err         t         P>|t|     2.5 %    97.5 %\n",
      "educ  0.105972  0.013733  7.716822  1.192662e-14  0.079057  0.132888\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from doubleml.datasets import make_plr_CCDDHNR2018\n",
    "from doubleml import DoubleMLData\n",
    "\n",
    "np.random.seed(1234)\n",
    "dml_data_bonus = DoubleMLData(df, y_col=outcome,\n",
    "                                  d_cols=treatment,\n",
    "                                  x_cols=list(rest))\n",
    "print(dml_data_bonus)\n",
    "from sklearn.base import clone\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LassoCV\n",
    "learner = RandomForestRegressor(n_estimators = 100, max_features = 'sqrt', max_depth= 6)\n",
    "ml_l_bonus = clone(learner)\n",
    "ml_m_bonus = clone(learner)\n",
    "learner = LassoCV()\n",
    "ml_l_sim = clone(learner)\n",
    "ml_m_sim = clone(learner)\n",
    "def non_orth_score(y, d, l_hat, m_hat, g_hat, smpls):\n",
    "    u_hat = y - g_hat\n",
    "    psi_a = -np.multiply(d, d)\n",
    "    psi_b = np.multiply(d, u_hat)\n",
    "    return psi_a, psi_b\n",
    "\n",
    "from doubleml import DoubleMLPLR\n",
    "np.random.seed(42)\n",
    "obj_dml_plr_bonus = DoubleMLPLR(dml_data_bonus, ml_l_bonus, ml_m_bonus, n_folds = 10)\n",
    "obj_dml_plr_bonus.fit();\n",
    "print(obj_dml_plr_bonus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "0c9d0077",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficient Results:  X is None, please call intercept_inference to learn the constant!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>CATE Intercept Results</caption>\n",
       "<tr>\n",
       "         <td></td>        <th>point_estimate</th> <th>stderr</th> <th>zstat</th> <th>pvalue</th> <th>ci_lower</th> <th>ci_upper</th>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>cate_intercept</th>      <td>0.112</td>      <td>0.014</td> <td>8.006</td>   <td>0.0</td>    <td>0.084</td>    <td>0.139</td> \n",
       "</tr>\n",
       "</table><br/><br/><sub>A linear parametric conditional average treatment effect (CATE) model was fitted:<br/>$Y = \\Theta(X)\\cdot T + g(X, W) + \\epsilon$<br/>where for every outcome $i$ and treatment $j$ the CATE $\\Theta_{ij}(X)$ has the form:<br/>$\\Theta_{ij}(X) = X' coef_{ij} + cate\\_intercept_{ij}$<br/>Coefficient Results table portrays the $coef_{ij}$ parameter vector for each outcome $i$ and treatment $j$. Intercept Results table portrays the $cate\\_intercept_{ij}$ parameter.</sub>"
      ],
      "text/plain": [
       "<class 'econml.utilities.Summary'>\n",
       "\"\"\"\n",
       "                       CATE Intercept Results                      \n",
       "===================================================================\n",
       "               point_estimate stderr zstat pvalue ci_lower ci_upper\n",
       "-------------------------------------------------------------------\n",
       "cate_intercept          0.112  0.014 8.006    0.0    0.084    0.139\n",
       "-------------------------------------------------------------------\n",
       "\n",
       "<sub>A linear parametric conditional average treatment effect (CATE) model was fitted:\n",
       "$Y = \\Theta(X)\\cdot T + g(X, W) + \\epsilon$\n",
       "where for every outcome $i$ and treatment $j$ the CATE $\\Theta_{ij}(X)$ has the form:\n",
       "$\\Theta_{ij}(X) = X' coef_{ij} + cate\\_intercept_{ij}$\n",
       "Coefficient Results table portrays the $coef_{ij}$ parameter vector for each outcome $i$ and treatment $j$. Intercept Results table portrays the $cate\\_intercept_{ij}$ parameter.</sub>\n",
       "\"\"\""
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# DML regression - still yeilds unbiased estimate of ATE \n",
    "from econml.dml import LinearDML\n",
    "est = LinearDML(random_state=45)\n",
    "est.fit(y, d, X=None,W=x)\n",
    "est.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96e5aa4f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
