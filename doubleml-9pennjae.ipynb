{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1cd77248",
   "metadata": {},
   "source": [
    "# Generate Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b68db5d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13913,) (13913, 15) (13913,)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "from doubleml.datasets import make_plr_CCDDHNR2018, make_plr_turrell2018\n",
    "np.random.seed(1234)\n",
    "n_rep = 1\n",
    "n_obs = 10000\n",
    "n_vars = 10\n",
    "alpha = 0.5\n",
    "data = list()\n",
    "from sklearn.datasets import make_spd_matrix\n",
    "\n",
    "def g(x):\n",
    "    return np.exp(x)\n",
    "\n",
    "def m(x):\n",
    "    return np.sin(x)\n",
    "\n",
    "theta = alpha = 0.5 \n",
    "b = [1/k for k in range(1,n_vars+1)] # x weights \n",
    "sigma = make_spd_matrix(n_vars, random_state=42)\n",
    "\n",
    "for i_rep in range(n_rep):\n",
    "    #(x, y, d) = make_plr_turrell2018(alpha=alpha, n_obs=n_obs, dim_x=n_vars, return_type='array')\n",
    "    df = pd.read_csv(\"/Users/pranjal/Desktop/Causal-Inference/data/penn_jae.dat\", sep = ' ')\n",
    "\n",
    "    outcome = 'inuidur1'\n",
    "    treatment = 'tg'\n",
    "    rest = list(df.drop([outcome, treatment, 'inuidur2','muld', 'Unnamed: 24', 'Unnamed: 25'], axis = 1).columns)\n",
    "    rest = ['female', 'black', 'othrace',\n",
    "       'dep', 'q1', 'q2', 'q3', 'q4', 'q5', 'q6', \n",
    "       'agelt35', 'agegt54', 'durable', 'lusd', 'husd']\n",
    "    df = df[[outcome] + [treatment] + rest]\n",
    "    df = df.dropna()\n",
    "    #df = df.fillna(0)\n",
    "    #df = df[df.avg <= 15]\n",
    "    y = df[outcome]\n",
    "    d = df[treatment]\n",
    "    x = df[rest].astype('float')\n",
    "    print(y.shape, x.shape, d.shape)\n",
    "    data.append((x, y, d))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8faf717c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['inuidur1', 'tg', 'female', 'black', 'othrace', 'dep', 'q1', 'q2', 'q3',\n",
       "       'q4', 'q5', 'q6', 'agelt35', 'agegt54', 'durable', 'lusd', 'husd'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "805d3762",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'female' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [18], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mfemale\u001b[49m\u001b[38;5;241m+\u001b[39mblack\u001b[38;5;241m+\u001b[39mothrace\u001b[38;5;241m+\u001b[39m dep\u001b[38;5;241m+\u001b[39mq2\u001b[38;5;241m+\u001b[39mq3\u001b[38;5;241m+\u001b[39mq4\u001b[38;5;241m+\u001b[39mq5\u001b[38;5;241m+\u001b[39mq6\u001b[38;5;241m+\u001b[39magelt35\u001b[38;5;241m+\u001b[39magegt54\u001b[38;5;241m+\u001b[39mdurable\u001b[38;5;241m+\u001b[39mlusd\u001b[38;5;241m+\u001b[39mhusd\n",
      "\u001b[0;31mNameError\u001b[0m: name 'female' is not defined"
     ]
    }
   ],
   "source": [
    "female+black+othrace+ dep+q2+q3+q4+q5+q6+agelt35+agegt54+durable+lusd+husd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27aa0664",
   "metadata": {},
   "source": [
    "# Naive ML\n",
    "- no orthogonalisation, no crossfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "58f81856",
   "metadata": {},
   "outputs": [],
   "source": [
    "def non_orth_score(y, d, l_hat, m_hat, g_hat, smpls):\n",
    "    psi_a = -np.multiply(d, d)\n",
    "    psi_b = np.multiply(d, y - g_hat)\n",
    "    return psi_a, psi_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a66b23e7",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'RandomForestRegressor' object has no attribute 'predict_proba'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [20], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mml_m\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43md\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict_proba\u001b[49m(x)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'RandomForestRegressor' object has no attribute 'predict_proba'"
     ]
    }
   ],
   "source": [
    "ml_m.fit(x,d).predict_proba(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "226e7de3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from doubleml import DoubleMLData\n",
    "from doubleml import DoubleMLPLR\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.base import clone\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "face_colors = sns.color_palette('pastel')\n",
    "edge_colors = sns.color_palette('dark')\n",
    "np.random.seed(1111)\n",
    "ml_l = RandomForestRegressor()\n",
    "ml_m = RandomForestRegressor()\n",
    "#ml_m = LogisticRegression()\n",
    "ml_g = clone(ml_l)\n",
    "\n",
    "# to speed up the illustration we hard-code the simulation results\n",
    "theta_nonorth = np.empty(n_rep)\n",
    "se_nonorth = np.empty(n_rep)\n",
    "t_nonorth = np.empty(n_rep)\n",
    "p_nonorth = np.empty(n_rep)\n",
    "# to run the full simulation uncomment the following line to fit the model for every dataset and not just for the first dataset\n",
    "for i_rep in range(n_rep):\n",
    "    print(i_rep)\n",
    "#for i_rep in range(1):\n",
    "    (x, y, d) = data[i_rep]\n",
    "    obj_dml_data = DoubleMLData.from_arrays(x, y.ravel(), d.ravel())\n",
    "    print(obj_dml_data)\n",
    "    obj_dml_plr_nonorth = DoubleMLPLR(obj_dml_data,\n",
    "                                      ml_l, ml_m, ml_g,\n",
    "                                      n_folds=2,\n",
    "                                      apply_cross_fitting=False,\n",
    "                                      score=non_orth_score)\n",
    "    obj_dml_plr_nonorth.fit()\n",
    "    theta_nonorth[i_rep] = obj_dml_plr_nonorth.coef[0]\n",
    "    se_nonorth[i_rep] = obj_dml_plr_nonorth.se[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c563855",
   "metadata": {},
   "source": [
    "# Orthogonal Machine Learning\n",
    "- resolves regularization bias, but not overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2682d65",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.random.seed(2222)\n",
    "# to speed up the illustration we hard-code the simulation results\n",
    "theta_orth_nosplit = np.empty(n_rep)\n",
    "se_orth_nosplit = np.empty(n_rep)\n",
    "# to run the full simulation uncomment the following line to fit the model for every dataset and not just for the first dataset\n",
    "for i_rep in range(n_rep):\n",
    "    print(i_rep)\n",
    "#for i_rep in range(1):\n",
    "    (x, y, d) = data[i_rep]\n",
    "    obj_dml_data = DoubleMLData.from_arrays(x, y, d)\n",
    "    obj_dml_plr_orth_nosplit = DoubleMLPLR(obj_dml_data,\n",
    "                                           ml_l, ml_m, ml_g,\n",
    "                                           n_folds=1,\n",
    "                                           score='IV-type',\n",
    "                                           apply_cross_fitting=False)\n",
    "    obj_dml_plr_orth_nosplit.fit()\n",
    "    theta_orth_nosplit[i_rep] = obj_dml_plr_orth_nosplit.coef[0]\n",
    "    se_orth_nosplit[i_rep] = obj_dml_plr_orth_nosplit.se[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caa0e04f",
   "metadata": {},
   "source": [
    "# Orthogonal ML + Cross fitting (DML)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1da32ff1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "# to speed up the illustration we hard-code the simulation results\n",
    "theta_dml = np.empty(n_rep)\n",
    "se_dml = np.empty(n_rep)\n",
    "\n",
    "# to run the full simulation uncomment the following line to fit the model for every dataset and not just for the first dataset\n",
    "for i_rep in range(n_rep):\n",
    "    print(i_rep)\n",
    "    (x, y, d) = data[i_rep]\n",
    "    obj_dml_data = DoubleMLData.from_arrays(x, y, d)\n",
    "    obj_dml_plr = DoubleMLPLR(obj_dml_data,\n",
    "                              ml_l, ml_m, ml_g,\n",
    "                              n_folds=2,\n",
    "                              score='IV-type')\n",
    "    obj_dml_plr.fit()\n",
    "    theta_dml[i_rep] = obj_dml_plr.coef[0]\n",
    "    se_dml[i_rep] = obj_dml_plr.se[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f2a68ee",
   "metadata": {},
   "source": [
    "# Regular OLS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1ca1516e",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "import statsmodels.api as sm # for OLS \n",
    "# to speed up the illustration we hard-code the simulation results\n",
    "theta_ols = np.empty(n_rep)\n",
    "se_ols = np.empty(n_rep)\n",
    "# to run the full simulation uncomment the following line to fit the model for every dataset and not just for the first dataset\n",
    "for i_rep in range(n_rep):\n",
    "    (x, y, d) = data[i_rep]\n",
    "    OLS = sm.OLS(y,sm.add_constant(np.c_[d,x]))\n",
    "    results = OLS.fit()\n",
    "    theta_ols[i_rep] = results.params[1]\n",
    "    se_ols[i_rep] = results.bse[1]   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ac75834",
   "metadata": {},
   "source": [
    "# Distribution of Theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "66d67e46",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------------+--------+-------+--------+-------+--------+--------+\n",
      "|            est             |  coef  |  std  |   t    |   p   |  2.5%  | 97.25% |\n",
      "+----------------------------+--------+-------+--------+-------+--------+--------+\n",
      "|            OLS             | -0.091 | 0.044 | -2.050 | 0.040 |  nan   |  nan   |\n",
      "|          Naive-ML          | -0.087 | 0.042 | -2.074 | 0.038 | -0.170 | -0.005 |\n",
      "|          Ortho-ML          | -0.122 | 0.042 | -2.920 | 0.003 | -0.205 | -0.040 |\n",
      "| OrthoML+Crossfitting (DML) | -0.062 | 0.047 | -1.318 | 0.188 | -0.154 | 0.030  |\n",
      "+----------------------------+--------+-------+--------+-------+--------+--------+\n"
     ]
    }
   ],
   "source": [
    "from prettytable import PrettyTable\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "MC_Î¸ = np.c_[theta_ols, theta_nonorth, theta_orth_nosplit, theta_dml]\n",
    "MC_se = np.c_[se_ols, se_nonorth, se_orth_nosplit, se_dml]\n",
    "\n",
    "table = PrettyTable()\n",
    "table.field_names = ['est', 'coef', 'std','t','p','2.5%','97.25%']\n",
    "a = ['OLS']+ np.c_[results.params[1], results.bse[1], results.tvalues[1], results.pvalues[1], np.nan, np.nan].reshape(-1).tolist()\n",
    "table.add_row(a)\n",
    "a = ['Naive-ML']+ np.array(obj_dml_plr_nonorth.summary).reshape(-1).tolist()\n",
    "table.add_row(a)\n",
    "a = ['Ortho-ML']+ np.array(obj_dml_plr_orth_nosplit.summary).reshape(-1).tolist()\n",
    "table.add_row(a)\n",
    "a = ['OrthoML+Crossfitting (DML)']+ np.array(obj_dml_plr.summary).reshape(-1).tolist()\n",
    "table.add_row(a)\n",
    "table.float_format = '0.3'\n",
    "print(table)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9027bc2",
   "metadata": {},
   "source": [
    "# First Stage Checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "d9b7a705",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>          <td>lwage</td>      <th>  R-squared:         </th> <td>   0.151</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.141</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   14.98</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Sun, 11 Dec 2022</td> <th>  Prob (F-statistic):</th> <td>1.52e-13</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>17:14:09</td>     <th>  Log-Likelihood:    </th> <td> -433.15</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   428</td>      <th>  AIC:               </th> <td>   878.3</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   422</td>      <th>  BIC:               </th> <td>   902.6</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     5</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td>   -0.2190</td> <td>    0.300</td> <td>   -0.729</td> <td> 0.466</td> <td>   -0.809</td> <td>    0.371</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1</th>    <td>    0.1096</td> <td>    0.014</td> <td>    7.600</td> <td> 0.000</td> <td>    0.081</td> <td>    0.138</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x2</th>    <td>    0.0155</td> <td>    0.005</td> <td>    3.261</td> <td> 0.001</td> <td>    0.006</td> <td>    0.025</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x3</th>    <td>   -0.0035</td> <td>    0.005</td> <td>   -0.666</td> <td> 0.505</td> <td>   -0.014</td> <td>    0.007</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x4</th>    <td>   -0.0755</td> <td>    0.089</td> <td>   -0.851</td> <td> 0.395</td> <td>   -0.250</td> <td>    0.099</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x5</th>    <td>   -0.0177</td> <td>    0.028</td> <td>   -0.632</td> <td> 0.528</td> <td>   -0.073</td> <td>    0.037</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>79.021</td> <th>  Durbin-Watson:     </th> <td>   1.985</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td> <th>  Jarque-Bera (JB):  </th> <td> 299.257</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td>-0.773</td> <th>  Prob(JB):          </th> <td>1.04e-65</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 6.793</td> <th>  Cond. No.          </th> <td>    433.</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                  lwage   R-squared:                       0.151\n",
       "Model:                            OLS   Adj. R-squared:                  0.141\n",
       "Method:                 Least Squares   F-statistic:                     14.98\n",
       "Date:                Sun, 11 Dec 2022   Prob (F-statistic):           1.52e-13\n",
       "Time:                        17:14:09   Log-Likelihood:                -433.15\n",
       "No. Observations:                 428   AIC:                             878.3\n",
       "Df Residuals:                     422   BIC:                             902.6\n",
       "Df Model:                           5                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const         -0.2190      0.300     -0.729      0.466      -0.809       0.371\n",
       "x1             0.1096      0.014      7.600      0.000       0.081       0.138\n",
       "x2             0.0155      0.005      3.261      0.001       0.006       0.025\n",
       "x3            -0.0035      0.005     -0.666      0.505      -0.014       0.007\n",
       "x4            -0.0755      0.089     -0.851      0.395      -0.250       0.099\n",
       "x5            -0.0177      0.028     -0.632      0.528      -0.073       0.037\n",
       "==============================================================================\n",
       "Omnibus:                       79.021   Durbin-Watson:                   1.985\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              299.257\n",
       "Skew:                          -0.773   Prob(JB):                     1.04e-65\n",
       "Kurtosis:                       6.793   Cond. No.                         433.\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "OLS = sm.OLS(y,sm.add_constant(np.c_[d, x]))\n",
    "results = OLS.fit()\n",
    "results.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "5a696896",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>          <td>educ</td>       <th>  R-squared:         </th> <td>   0.031</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.022</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   3.366</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Sun, 11 Dec 2022</td> <th>  Prob (F-statistic):</th>  <td>0.00997</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>17:14:12</td>     <th>  Log-Likelihood:    </th> <td> -953.86</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   428</td>      <th>  AIC:               </th> <td>   1918.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   423</td>      <th>  BIC:               </th> <td>   1938.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     4</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td>   13.6328</td> <td>    0.766</td> <td>   17.806</td> <td> 0.000</td> <td>   12.128</td> <td>   15.138</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1</th>    <td>   -0.0049</td> <td>    0.016</td> <td>   -0.305</td> <td> 0.761</td> <td>   -0.036</td> <td>    0.027</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x2</th>    <td>   -0.0166</td> <td>    0.018</td> <td>   -0.947</td> <td> 0.344</td> <td>   -0.051</td> <td>    0.018</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x3</th>    <td>    0.6948</td> <td>    0.297</td> <td>    2.337</td> <td> 0.020</td> <td>    0.111</td> <td>    1.279</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x4</th>    <td>   -0.2298</td> <td>    0.094</td> <td>   -2.456</td> <td> 0.014</td> <td>   -0.414</td> <td>   -0.046</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td> 4.161</td> <th>  Durbin-Watson:     </th> <td>   1.949</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.125</td> <th>  Jarque-Bera (JB):  </th> <td>   4.351</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 0.141</td> <th>  Prob(JB):          </th> <td>   0.114</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 3.406</td> <th>  Cond. No.          </th> <td>    318.</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                   educ   R-squared:                       0.031\n",
       "Model:                            OLS   Adj. R-squared:                  0.022\n",
       "Method:                 Least Squares   F-statistic:                     3.366\n",
       "Date:                Sun, 11 Dec 2022   Prob (F-statistic):            0.00997\n",
       "Time:                        17:14:12   Log-Likelihood:                -953.86\n",
       "No. Observations:                 428   AIC:                             1918.\n",
       "Df Residuals:                     423   BIC:                             1938.\n",
       "Df Model:                           4                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const         13.6328      0.766     17.806      0.000      12.128      15.138\n",
       "x1            -0.0049      0.016     -0.305      0.761      -0.036       0.027\n",
       "x2            -0.0166      0.018     -0.947      0.344      -0.051       0.018\n",
       "x3             0.6948      0.297      2.337      0.020       0.111       1.279\n",
       "x4            -0.2298      0.094     -2.456      0.014      -0.414      -0.046\n",
       "==============================================================================\n",
       "Omnibus:                        4.161   Durbin-Watson:                   1.949\n",
       "Prob(Omnibus):                  0.125   Jarque-Bera (JB):                4.351\n",
       "Skew:                           0.141   Prob(JB):                        0.114\n",
       "Kurtosis:                       3.406   Cond. No.                         318.\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "OLS = sm.OLS(d,sm.add_constant(np.c_[x]))\n",
    "results = OLS.fit()\n",
    "results.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "a419c862",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'DataFrame' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [93], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mobj_dml_plr_nonorth\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msummary\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'DataFrame' object is not callable"
     ]
    }
   ],
   "source": [
    "obj_dml_plr_nonorth.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2985af4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
